
export ZOOKEEPER_HOME=/usr/local/apache-zookeeper-3.5.5
export PATH=$PATH:$ZOOKEEPER_HOME/bin

export HADOOP_HOME=/usr/local/hadoop-3.1.2
export PATH=$PATH:$HADOOP_HOME/bin



1、
$ vim sbin/start-dfs.sh
$ vim sbin/stop-dfs.sh 

HDFS_DATANODE_USER=root
HADOOP_SECURE_DN_USER=hdfs
HDFS_NAMENODE_USER=root
HDFS_SECONDARYNAMENODE_USER=root 

2、
$ vim sbin/start-yarn.sh
$ vim sbin/stop-yarn.sh 

YARN_RESOURCEMANAGER_USER=root
HADOOP_SECURE_DN_USER=yarn
YARN_NODEMANAGER_USER=root


运行：
bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep /user/hadoop/input output 'dfs[a-z.]+'


输出:
root@master:/usr/local/hadoop-3.1.2# bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep /user/hadoop/input output 'dfs[a-z.]+'
2019-09-14 14:51:32,608 INFO client.RMProxy: Connecting to ResourceManager at master/172.17.0.2:8032
2019-09-14 14:51:33,156 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1568461511563_0005
2019-09-14 14:51:33,364 INFO input.FileInputFormat: Total input files to process : 9
2019-09-14 14:51:33,434 INFO mapreduce.JobSubmitter: number of splits:9
2019-09-14 14:51:33,564 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1568461511563_0005
2019-09-14 14:51:33,565 INFO mapreduce.JobSubmitter: Executing with tokens: []
2019-09-14 14:51:33,722 INFO conf.Configuration: resource-types.xml not found
2019-09-14 14:51:33,722 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2019-09-14 14:51:33,778 INFO impl.YarnClientImpl: Submitted application application_1568461511563_0005
2019-09-14 14:51:33,812 INFO mapreduce.Job: The url to track the job: http://master:8088/proxy/application_1568461511563_0005/
2019-09-14 14:51:33,813 INFO mapreduce.Job: Running job: job_1568461511563_0005
2019-09-14 14:51:39,911 INFO mapreduce.Job: Job job_1568461511563_0005 running in uber mode : false
2019-09-14 14:51:39,914 INFO mapreduce.Job:  map 0% reduce 0%
2019-09-14 14:51:48,037 INFO mapreduce.Job:  map 67% reduce 0%
2019-09-14 14:51:53,066 INFO mapreduce.Job:  map 100% reduce 0%
2019-09-14 14:51:54,076 INFO mapreduce.Job:  map 100% reduce 100%
2019-09-14 14:51:54,096 INFO mapreduce.Job: Job job_1568461511563_0005 completed successfully
2019-09-14 14:51:54,199 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=115
		FILE: Number of bytes written=2164513
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=29572
		HDFS: Number of bytes written=219
		HDFS: Number of read operations=32
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Killed map tasks=1
		Launched map tasks=9
		Launched reduce tasks=1
		Data-local map tasks=9
		Total time spent by all maps in occupied slots (ms)=43902
		Total time spent by all reduces in occupied slots (ms)=3644
		Total time spent by all map tasks (ms)=43902
		Total time spent by all reduce tasks (ms)=3644
		Total vcore-milliseconds taken by all map tasks=43902
		Total vcore-milliseconds taken by all reduce tasks=3644
		Total megabyte-milliseconds taken by all map tasks=44955648
		Total megabyte-milliseconds taken by all reduce tasks=3731456
	Map-Reduce Framework
		Map input records=773
		Map output records=4
		Map output bytes=101
		Map output materialized bytes=163
		Input split bytes=1050
		Combine input records=4
		Combine output records=4
		Reduce input groups=4
		Reduce shuffle bytes=163
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=1459
		CPU time spent (ms)=5770
		Physical memory (bytes) snapshot=3385409536
		Virtual memory (bytes) snapshot=26512478208
		Total committed heap usage (bytes)=3307732992
		Peak Map Physical memory (bytes)=359833600
		Peak Map Virtual memory (bytes)=2651484160
		Peak Reduce Physical memory (bytes)=263991296
		Peak Reduce Virtual memory (bytes)=2659270656
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=28522
	File Output Format Counters 
		Bytes Written=219
2019-09-14 14:51:54,229 INFO client.RMProxy: Connecting to ResourceManager at master/172.17.0.2:8032
2019-09-14 14:51:54,245 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1568461511563_0006
2019-09-14 14:51:54,279 INFO input.FileInputFormat: Total input files to process : 1
2019-09-14 14:51:54,325 INFO mapreduce.JobSubmitter: number of splits:1
2019-09-14 14:51:54,371 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1568461511563_0006
2019-09-14 14:51:54,372 INFO mapreduce.JobSubmitter: Executing with tokens: []
2019-09-14 14:51:54,393 INFO impl.YarnClientImpl: Submitted application application_1568461511563_0006
2019-09-14 14:51:54,399 INFO mapreduce.Job: The url to track the job: http://master:8088/proxy/application_1568461511563_0006/
2019-09-14 14:51:54,399 INFO mapreduce.Job: Running job: job_1568461511563_0006
2019-09-14 14:52:06,558 INFO mapreduce.Job: Job job_1568461511563_0006 running in uber mode : false
2019-09-14 14:52:06,559 INFO mapreduce.Job:  map 0% reduce 0%

2019-09-14 14:52:10,597 INFO mapreduce.Job:  map 100% reduce 0%
2019-09-14 14:52:15,633 INFO mapreduce.Job:  map 100% reduce 100%
2019-09-14 14:52:16,660 INFO mapreduce.Job: Job job_1568461511563_0006 completed successfully
2019-09-14 14:52:16,715 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=115
		FILE: Number of bytes written=431883
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=346
		HDFS: Number of bytes written=77
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2202
		Total time spent by all reduces in occupied slots (ms)=2438
		Total time spent by all map tasks (ms)=2202
		Total time spent by all reduce tasks (ms)=2438
		Total vcore-milliseconds taken by all map tasks=2202
		Total vcore-milliseconds taken by all reduce tasks=2438
		Total megabyte-milliseconds taken by all map tasks=2254848
		Total megabyte-milliseconds taken by all reduce tasks=2496512
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=101
		Map output materialized bytes=115
		Input split bytes=127
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=115
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=83
		CPU time spent (ms)=1120
		Physical memory (bytes) snapshot=609632256
		Virtual memory (bytes) snapshot=5310267392
		Total committed heap usage (bytes)=609222656
		Peak Map Physical memory (bytes)=357404672
		Peak Map Virtual memory (bytes)=2653884416
		Peak Reduce Physical memory (bytes)=252227584
		Peak Reduce Virtual memory (bytes)=2656382976
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=219
	File Output Format Counters 
		Bytes Written=77


修改：
/usr/local/hadoop-3.1.2/etc/hadoop/mapred-site.xml

<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>yarn.app.mapreduce.am.env</name>
        <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
    </property>
    <property>
        <name>mapreduce.map.env</name>
        <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
    </property>
    <property>
        <name>mapreduce.reduce.env</name>
        <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
    </property>
</configuration>


Spark配置

# Options read when launching programs locally with
# ./bin/run-example or ./bin/spark-submit
# - HADOOP_CONF_DIR, to point Spark towards Hadoop configuration files
# - SPARK_LOCAL_IP, to set the IP address Spark binds to on this node
# - SPARK_PUBLIC_DNS, to set the public dns name of the driver program

# Options read by executors and drivers running inside the cluster
# - SPARK_LOCAL_IP, to set the IP address Spark binds to on this node
# - SPARK_PUBLIC_DNS, to set the public DNS name of the driver program
# - SPARK_LOCAL_DIRS, storage directories to use on this node for shuffle and RDD data
# - MESOS_NATIVE_JAVA_LIBRARY, to point to your libmesos.so if you use Mesos

# Options read in YARN client/cluster mode
# - SPARK_CONF_DIR, Alternate conf dir. (Default: ${SPARK_HOME}/conf)
# - HADOOP_CONF_DIR, to point Spark towards Hadoop configuration files
# - YARN_CONF_DIR, to point Spark towards YARN configuration files when you use YARN
# - SPARK_EXECUTOR_CORES, Number of cores for the executors (Default: 1).
# - SPARK_EXECUTOR_MEMORY, Memory per Executor (e.g. 1000M, 2G) (Default: 1G)
# - SPARK_DRIVER_MEMORY, Memory for Driver (e.g. 1000M, 2G) (Default: 1G)

# Options for the daemons used in the standalone deploy mode
# - SPARK_MASTER_HOST, to bind the master to a different IP address or hostname
# - SPARK_MASTER_PORT / SPARK_MASTER_WEBUI_PORT, to use non-default ports for the master
# - SPARK_MASTER_OPTS, to set config properties only for the master (e.g. "-Dx=y")
# - SPARK_WORKER_CORES, to set the number of cores to use on this machine
# - SPARK_WORKER_MEMORY, to set how much total memory workers have to give executors (e.g. 1000m, 2g)
# - SPARK_WORKER_PORT / SPARK_WORKER_WEBUI_PORT, to use non-default ports for the worker
# - SPARK_WORKER_DIR, to set the working directory of worker processes
# - SPARK_WORKER_OPTS, to set config properties only for the worker (e.g. "-Dx=y")
# - SPARK_DAEMON_MEMORY, to allocate to the master, worker and history server themselves (default: 1g).
# - SPARK_HISTORY_OPTS, to set config properties only for the history server (e.g. "-Dx=y")
# - SPARK_SHUFFLE_OPTS, to set config properties only for the external shuffle service (e.g. "-Dx=y")
# - SPARK_DAEMON_JAVA_OPTS, to set config properties for all daemons (e.g. "-Dx=y")
# - SPARK_DAEMON_CLASSPATH, to set the classpath for all daemons
# - SPARK_PUBLIC_DNS, to set the public dns name of the master or workers

# Generic options for the daemons used in the standalone deploy mode
# - SPARK_CONF_DIR      Alternate conf dir. (Default: ${SPARK_HOME}/conf)
# - SPARK_LOG_DIR       Where log files are stored.  (Default: ${SPARK_HOME}/logs)
# - SPARK_PID_DIR       Where the pid file is stored. (Default: /tmp)
# - SPARK_IDENT_STRING  A string representing this instance of spark. (Default: $USER)
# - SPARK_NICENESS      The scheduling priority for daemons. (Default: 0)
# - SPARK_NO_DAEMONIZE  Run the proposed command in the foreground. It will not output a PID file.
# Options for native BLAS, like Intel MKL, OpenBLAS, and so on.
# You might get better performance to enable these options if using native BLAS (see SPARK-21305).
# - MKL_NUM_THREADS=1        Disable multi-threading of Intel MKL
# - OPENBLAS_NUM_THREADS=1   Disable multi-threading of OpenBLAS

export JAVA_HOME=/usr/local/jdk1.8.0_181
export SCALA_HOME=/usr/local/scala-2.12.6
export HADOOP_HOME=/usr/local/spark-2.4.4-bin-hadoop2.7
export SPARK_MASTER_HOST=172.17.0.2
export SPARK_MASTER_PORT=7077
export SPARK_MASTER_WEBUI_PORT=7070
export SPARK_WORKER_CORES=2
export SPARK_WORKER_MEMORY=1024m
export SPARK_WORKER_INSTANCES=2
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export SPARK_YARN_USER_ENV="CLASSPATH=/usr/local/hadoop-3.1.2/etc/hadoop"
export SPARK_CLASSPATH=$HBASE_HOME/lib/hbase-protocol-1.2.4.jar:$HBASE_HOME/lib/hbase-common-1.2.4.jar:$HBASE_HOME/lib/htrace-core-3.1.0-incubating.jar:$HBASE_HOME/lib/hbase-server-1.2.4.jar:$HBASE_HOME/lib/hbase-client-1.2.4.jar:$HBASE_HOME/lib/metrics-core-2.2.0.jar:$SPARK_CLASSPATH
export SPARK_LOCAL_DIR="/mnt/spark/tmp"
export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop
export SPARK_JAVA_OPTS="-Dspark.storage.blockManagerHeartBeatMs=60000-Dspark.local.dir=$SPARK_LOCAL_DIR -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:$SPARK_HOME/logs/gc.log -XX:+UseConcMarkSweepGC -XX:+UseCMSCompactAtFullCollection -XX:CMSInitiatingOccupancyFraction=60"
export SPARK_DAEMON_JAVA_OPTS="-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=hadoop-2:2181,hadoop-3:2181,hadoop-5:2181 -Dspark.deploy.zookeeper.dir=/spark"


